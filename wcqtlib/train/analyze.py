import logging
import numpy as np
import os
import pandas
import sklearn.metrics

import wcqtlib.common.utils as utils

logger = logging.getLogger(__name__)

DATASETS = ["rwc", "uiowa", "philharmonia"]


def concat_dataset_column(predictions_df, features_df):
    """Joins the features and predictions on the index, and
    concatenates the "dataset" field from features_df to the
    predictions_df.

    Returns
    -------
    joined_predictions : pandas.DataFrame
        predictions_df including the dataset.
    """
    return pandas.concat([
        predictions_df,
        features_df[features_df.index.isin(predictions_df.index)]['dataset']],
        axis=1)


class PredictionAnalyzer(object):
    """Worker class which cretes analysis dataframes from
    the predictions.
    """

    def __init__(self, predictions_df, features_df=None, test_set=None):
        """
        Parameters
        ----------
        predictions_df : pandas.DataFrame
            DataFrame containing predictions generated by
            evaluate.evaluate_df. Indeces from the predictions_df
            should match indeces in the features_df.

        features_df : pandas.DataFrame or None
            DataFrame pointing to the original audio, features, and
            all associated metadata.

        test_set : str in ["rwc", "uiowa", "philharmonia"] or None
            Operates only on files from the dataset specified.
            Or, if None, operates on all files.
        """
        if features_df is not None:
            self.predictions_df = concat_dataset_column(
                predictions_df, features_df, test_set)
        else:
            if test_set is not None and \
                    "dataset" not in predictions_df.columns:
                raise KeyError("You must either provide the features_df "
                               "or the dataset column in the predictions_df.")
            self.predictions_df = predictions_df

        self.set_test_set(test_set)

    @property
    def view(self):
        """Provides a view on the predictions_df restricted to the test
        set chosen."""
        return self._view

    @classmethod
    def from_config(cls, config, experiment_name, model_name, test_set):
        features_path = os.path.join(
            os.path.expanduser(config["paths/extract_dir"]),
            config["dataframes/features"])
        experiment_dir = os.path.join(
            os.path.expanduser(config['paths/model_dir']),
            experiment_name)
        model_name = utils.iter_from_params_filepath(model_name)
        predictions_df_path = os.path.join(
            experiment_dir,
            config.get('experiment/predictions_format', None)
            .format(model_name))

        features_df = pandas.read_pickle(features_path)
        predictions_df = pandas.read_pickle(predictions_df_path)

        return cls(predictions_df, features_df, test_set)

    def set_test_set(self, test_set):
        if test_set is not None and test_set not in DATASETS:
            raise ValueError("{} is not a valid dataset.".format(test_set))

        self.test_set = test_set
        if self.test_set is not None:
            # set up a cache to make this faster
            self._view = self.predictions_df[
                self.predictions_df["dataset"] == self.test_set]
        else:
            self._view = self.predictions_df

    def save(self, write_path):
        """
        Parameters
        ----------
        write_path : str
            Serialize this class so we can reuse it later. Path should
            be a 'pkl' file.
        """
        self.predictions_df.to_pickle(write_path)

    @classmethod
    def load(cls, read_path, test_set=None):
        """
        Parameters
        ----------
        read_path : str
            Path to deserialize the analysis from.
        """
        pred_df = pandas.read_pickle(read_path)
        return cls(pred_df, test_set=test_set)

    @property
    def y_true(self):
        return self.view["target"].tolist()

    @property
    def y_pred(self):
        return self.view["max_likelyhood"].tolist()

    @property
    def mean_loss(self):
        return self.view["mean_loss"].mean()

    @property
    def accuracy(self):
        return self.tps.sum().mean()

    @property
    def tps(self):
        return self.view["max_likelyhood"] == self.view["target"]

    @property
    def support(self):
        return np.bincount(self.view["target"])

    @property
    def classes(self):
        if not hasattr(self, "_classes"):
            self._classes = sorted(np.unique(self.predictions_df["target"]))

        return self._classes

    @property
    def confusion_matrix(self):
        return sklearn.metrics.confusion_matrix(self.y_true, self.y_pred)

    @property
    def classification_report(self):
        return sklearn.metrics.classification_report(self.y_true, self.y_pred)

    def class_wise_scores(self):
        """
        Return a pandas DataFrame for scores for each class,
        where the scores are the columns, and the classes are the index.
        """
        precision = sklearn.metrics.precision_score(
            self.y_true, self.y_pred, labels=self.classes, average=None)
        recall = sklearn.metrics.recall_score(
            self.y_true, self.y_pred, labels=self.classes, average=None)
        f1score = sklearn.metrics.f1_score(
            self.y_true, self.y_pred, labels=self.classes, average=None)

        return pandas.DataFrame({
            "precision": precision,
            "recall": recall,
            "f1score": f1score,
            "support": self.support})

    def summary_scores(self):
        """Return summary scores over the entire dataset."""
        accuracy = sklearn.metrics.accuracy_score(
            self.y_true, self.y_pred)
        precision = sklearn.metrics.precision_score(
            self.y_true, self.y_pred, average="weighted")
        recall = sklearn.metrics.recall_score(
            self.y_true, self.y_pred, average="weighted")
        f1score = sklearn.metrics.f1_score(
            self.y_true, self.y_pred, average="weighted")
        return pandas.Series([accuracy, precision, recall, f1score],
                             index=["accuracy", "precision",
                                    "recall", "f1score"])
